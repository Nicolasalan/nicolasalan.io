{
  "title": "Vision Transformer (ViT) - Resumo",
  "summary": "Reconhecimento de imagem com o Vision Transformer (ViT)",
  "publishedAt": "2024-01-02",
  "tags": [
    "Pytorch",
    "ViT",
    "Transformer",
    "Vision"
  ],
  "shortTitle": "ViT",
  "body": {
    "raw": "\nBasicamente toda a arquitetura de modelos de *deep learning* é construído por camadas,\ncada camada executa uma função, um conjunto de camadas é um bloco e um conjunto\nde blocos forma um modelo.\n\n<Image rounded width={600} height={400} caption=\"Blocos do Transformers\" src=\"/blog/transformer/blocks.png\" />\n\nO modelo **`Vit Tranformer`** é dividido nas seguintes partes:\n\n<Image rounded width={600} height={400} caption=\"Blocos do Transformers\" src=\"/blog/transformer/block.png\" />\n\n#### 1. **Incorporação de patch + posição (entradas):**\n\n    Nessa parte ele divide as entradas no caso imagens em patch, além disso incorpora uma posição em cada patch para saber como a ordem.\n\n#### 2. ***Embedded Patches*:**\n\n    Nessa parte ele faz uma incorporação, assim que chamam onde seria transformar em um material que seria mais fácil de aprender para um IA, basicamente seria uma vetorização.\n\n#### 3. **Normalização:**\n\n    Normalizar a camada para evitar o *overfitting*.\n\n#### 4. **Atenção multicabeças:**\n\n    É aqui que a atenção é incorporada, também chamada de MSA, o pytorch já tem uma função para isso `[torch.nn.MultiheadAttention()`.\n\n#### 5. **MLP:**\n\n    *Perception* multi camada ou qualquer outra camada totalmente conectar como o linear que passa pelo *forward*. No próprio artigo possui uma camada linear, uma ativação não linear GELU e um *Dropout*.\n\n#### 6. ***Transformer Encoder*:**\n\n    Nessa parte é o decodificador onde na arquitetura *transformers* possui vários.\n\n#### 7. **MLP Head:**\n\n    Aqui somente produz a saída desejada.\n\n<Image rounded width={600} height={400} caption=\"4 Equações Gerais\" src=\"/blog/transformer/math.png\" />\n\n## Resumo de cada uma das equações:\n\n### 1) Embeddings de patch\nO Transformer utiliza um vetor latente constante `(uma dimensão definida, o termo \"vetor latente\" se refere a uma\nRepresentação de cada característica da entrada)` e mapeia cada vetor em 1D, pois é mais \"treinável\" para a máquina. \nFazer essa transformação é chamado de **embeddings de patch**, que seria vetorizar os valores e deixar em uma dimensão só, além de \nadicionar uma posição para cada patch, para saber a ordem.\n\n### 2) Codificador Transformer\nO codificador consiste em várias camadas de auto atenção chamadas de **Multi-Head Self-Attention (MSA)**,\nO layer Norm é aplicado antes de cada bloco e uma conexão residual após os blocos.\n\n### 3) Mesmo que a 2.\nMesma equação realizado na 2.\n\n### 4) Tokenização\nAdicionamos um token na sequência de patchs e produzir uma saída para o modelo.\n\n<Image rounded width={600} height={400} caption=\"Relação dos blocos\" src=\"/blog/transformer/equations.png\" />\n\n### Para mais detalhes:\n\n#### Visão geral da Equação 1\n\n<MathBlock caption=\"Equação Z0\">\n  {\"Z_0 = [X_{class}; X_{2p}E; ...;X_{np}E]+E_{pos}, E R^{(p^2*C)^D}, E_{pos} R^{(N*1)^D}\"}\n</MathBlock>\n\nEquação da tokenização !!!, onde enfim incorpora os patchs e a posição nos valores de entradas.\n`O valores de entradas podem ser uma imagem, textou ou qualquer outro tipo de dado.`\n\nUm pseudocódigo:\n\n```python\nx_input = [class_token, image_patch_1, image_patch_2, image_patch_3...] + \n[class_token_position, image_patch_1_position, image_patch_2_position, \nimage_patch_3_position...]\n``` \n\nOnde cada vetor dessa lista/vetor pode ser aprendido. `requires_grad=True`\n\n#### Visão geral da Equação 2\n\n<MathBlock caption=\"Equação Zl\">\n  {\"Z_l = MSA(LN(Z_{l-1})) + Z_{l-1}, l=1...L\"}\n</MathBlock>\n\nNessa equação mostra que para cada camada, existe um MSA envolvendo uma camada layer norm (LN).\nA adição final é uma conexão residual, que é basicamente adicionar as informações originais a saída. Ou seja, o modelo\ndiz simplesmente:\n> Mantenha parte da informação original, pois ela pode ser útil!\n\n<Image rounded width={600} height={400} caption=\"Conexão residual\" src=\"/blog/transformer/residual.png\" />\n\nUm pseudocódigo:\n```python\nx_output_MSA_block = MSA_layer(LN_layer(x_input)) + x_input\n```\n#### Visão geral da Equação 3\n\n<MathBlock caption=\"Equação Zl\">\n  {\"Z_l = MLP(LN(Z_{l}')) + Z_{l}, l=1...L\"}\n</MathBlock>\n\nA equação é quase o mesmo que a equação 2, porém com uma MLP (Multi Layer Perception) no final, ao invés de uma MSA, envolto de uma (LN).\n\nUm pseudocódigo:\n```python\nx_output_MLP_block = MLP_layer(LN_layer(x_output_MSA_block)) + x_output_MSA_block\n```\n#### Visão geral da Equação 4\n\n<MathBlock caption=\"Equação final\">\n  {\"y = LN(Z_l^0)\"}\n</MathBlock>\n\nPara última camada, a saída é um token de índice 0, envolto de uma camada (LN).\n\nUm pseudocódigo:\n```python\ny = Linear_layer(LN_layer(x_output_MLP_block[0]))\n```",
    "code": "var Component=(()=>{var m=Object.create;var s=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var _=(n,a)=>()=>(a||n((a={exports:{}}).exports,a),a.exports),k=(n,a)=>{for(var o in a)s(n,o,{get:a[o],enumerable:!0})},c=(n,a,o,r)=>{if(a&&typeof a==\"object\"||typeof a==\"function\")for(let i of h(a))!N.call(n,i)&&i!==o&&s(n,i,{get:()=>a[i],enumerable:!(r=u(a,i))||r.enumerable});return n};var f=(n,a,o)=>(o=n!=null?m(g(n)):{},c(a||!n||!n.__esModule?s(o,\"default\",{value:n,enumerable:!0}):o,n)),q=n=>c(s({},\"__esModule\",{value:!0}),n);var d=_((L,t)=>{t.exports=_jsx_runtime});var x={};k(x,{default:()=>M,frontmatter:()=>b});var e=f(d()),b={title:\"Vision Transformer (ViT) - Resumo\",publishedAt:\"2024-01-02\",summary:\"Reconhecimento de imagem com o Vision Transformer (ViT)\",tags:[\"Pytorch\",\"ViT\",\"Transformer\",\"Vision\"],shortTitle:\"ViT\"};function l(n){let a=Object.assign({p:\"p\",em:\"em\",strong:\"strong\",code:\"code\",h4:\"h4\",h2:\"h2\",h3:\"h3\",pre:\"pre\",span:\"span\",blockquote:\"blockquote\"},n.components),{Image:o,MathBlock:r}=a;return o||p(\"Image\",!0),r||p(\"MathBlock\",!0),(0,e.jsxs)(e.Fragment,{children:[(0,e.jsxs)(a.p,{children:[\"Basicamente toda a arquitetura de modelos de \",(0,e.jsx)(a.em,{children:\"deep learning\"}),` \\xE9 constru\\xEDdo por camadas,\ncada camada executa uma fun\\xE7\\xE3o, um conjunto de camadas \\xE9 um bloco e um conjunto\nde blocos forma um modelo.`]}),`\n`,(0,e.jsx)(o,{rounded:!0,width:600,height:400,caption:\"Blocos do Transformers\",src:\"/blog/transformer/blocks.png\"}),`\n`,(0,e.jsxs)(a.p,{children:[\"O modelo \",(0,e.jsx)(a.strong,{children:(0,e.jsx)(a.code,{children:\"Vit Tranformer\"})}),\" \\xE9 dividido nas seguintes partes:\"]}),`\n`,(0,e.jsx)(o,{rounded:!0,width:600,height:400,caption:\"Blocos do Transformers\",src:\"/blog/transformer/block.png\"}),`\n`,(0,e.jsxs)(a.h4,{id:\"1-incorpora\\xE7\\xE3o-de-patch--posi\\xE7\\xE3o-entradas\",children:[\"1. \",(0,e.jsx)(a.strong,{children:\"Incorpora\\xE7\\xE3o de patch + posi\\xE7\\xE3o (entradas):\"})]}),`\n`,(0,e.jsx)(a.p,{children:\"Nessa parte ele divide as entradas no caso imagens em patch, al\\xE9m disso incorpora uma posi\\xE7\\xE3o em cada patch para saber como a ordem.\"}),`\n`,(0,e.jsxs)(a.h4,{id:\"2-embedded-patches\",children:[\"2. \",(0,e.jsxs)(a.strong,{children:[(0,e.jsx)(a.em,{children:\"Embedded Patches\"}),\":\"]})]}),`\n`,(0,e.jsx)(a.p,{children:\"Nessa parte ele faz uma incorpora\\xE7\\xE3o, assim que chamam onde seria transformar em um material que seria mais f\\xE1cil de aprender para um IA, basicamente seria uma vetoriza\\xE7\\xE3o.\"}),`\n`,(0,e.jsxs)(a.h4,{id:\"3-normaliza\\xE7\\xE3o\",children:[\"3. \",(0,e.jsx)(a.strong,{children:\"Normaliza\\xE7\\xE3o:\"})]}),`\n`,(0,e.jsxs)(a.p,{children:[\"Normalizar a camada para evitar o \",(0,e.jsx)(a.em,{children:\"overfitting\"}),\".\"]}),`\n`,(0,e.jsxs)(a.h4,{id:\"4-aten\\xE7\\xE3o-multicabe\\xE7as\",children:[\"4. \",(0,e.jsx)(a.strong,{children:\"Aten\\xE7\\xE3o multicabe\\xE7as:\"})]}),`\n`,(0,e.jsxs)(a.p,{children:[\"\\xC9 aqui que a aten\\xE7\\xE3o \\xE9 incorporada, tamb\\xE9m chamada de MSA, o pytorch j\\xE1 tem uma fun\\xE7\\xE3o para isso \",(0,e.jsx)(a.code,{children:\"[torch.nn.MultiheadAttention()\"}),\".\"]}),`\n`,(0,e.jsxs)(a.h4,{id:\"5-mlp\",children:[\"5. \",(0,e.jsx)(a.strong,{children:\"MLP:\"})]}),`\n`,(0,e.jsxs)(a.p,{children:[(0,e.jsx)(a.em,{children:\"Perception\"}),\" multi camada ou qualquer outra camada totalmente conectar como o linear que passa pelo \",(0,e.jsx)(a.em,{children:\"forward\"}),\". No pr\\xF3prio artigo possui uma camada linear, uma ativa\\xE7\\xE3o n\\xE3o linear GELU e um \",(0,e.jsx)(a.em,{children:\"Dropout\"}),\".\"]}),`\n`,(0,e.jsxs)(a.h4,{id:\"6-transformer-encoder\",children:[\"6. \",(0,e.jsxs)(a.strong,{children:[(0,e.jsx)(a.em,{children:\"Transformer Encoder\"}),\":\"]})]}),`\n`,(0,e.jsxs)(a.p,{children:[\"Nessa parte \\xE9 o decodificador onde na arquitetura \",(0,e.jsx)(a.em,{children:\"transformers\"}),\" possui v\\xE1rios.\"]}),`\n`,(0,e.jsxs)(a.h4,{id:\"7-mlp-head\",children:[\"7. \",(0,e.jsx)(a.strong,{children:\"MLP Head:\"})]}),`\n`,(0,e.jsx)(a.p,{children:\"Aqui somente produz a sa\\xEDda desejada.\"}),`\n`,(0,e.jsx)(o,{rounded:!0,width:600,height:400,caption:\"4 Equa\\xE7\\xF5es Gerais\",src:\"/blog/transformer/math.png\"}),`\n`,(0,e.jsx)(a.h2,{id:\"resumo-de-cada-uma-das-equa\\xE7\\xF5es\",children:\"Resumo de cada uma das equa\\xE7\\xF5es:\"}),`\n`,(0,e.jsx)(a.h3,{id:\"1-embeddings-de-patch\",children:\"1) Embeddings de patch\"}),`\n`,(0,e.jsxs)(a.p,{children:[\"O Transformer utiliza um vetor latente constante \",(0,e.jsx)(a.code,{children:'(uma dimens\\xE3o definida, o termo \"vetor latente\" se refere a uma Representa\\xE7\\xE3o de cada caracter\\xEDstica da entrada)'}),` e mapeia cada vetor em 1D, pois \\xE9 mais \"trein\\xE1vel\" para a m\\xE1quina.\nFazer essa transforma\\xE7\\xE3o \\xE9 chamado de `,(0,e.jsx)(a.strong,{children:\"embeddings de patch\"}),`, que seria vetorizar os valores e deixar em uma dimens\\xE3o s\\xF3, al\\xE9m de\nadicionar uma posi\\xE7\\xE3o para cada patch, para saber a ordem.`]}),`\n`,(0,e.jsx)(a.h3,{id:\"2-codificador-transformer\",children:\"2) Codificador Transformer\"}),`\n`,(0,e.jsxs)(a.p,{children:[\"O codificador consiste em v\\xE1rias camadas de auto aten\\xE7\\xE3o chamadas de \",(0,e.jsx)(a.strong,{children:\"Multi-Head Self-Attention (MSA)\"}),`,\nO layer Norm \\xE9 aplicado antes de cada bloco e uma conex\\xE3o residual ap\\xF3s os blocos.`]}),`\n`,(0,e.jsx)(a.h3,{id:\"3-mesmo-que-a-2\",children:\"3) Mesmo que a 2.\"}),`\n`,(0,e.jsx)(a.p,{children:\"Mesma equa\\xE7\\xE3o realizado na 2.\"}),`\n`,(0,e.jsx)(a.h3,{id:\"4-tokeniza\\xE7\\xE3o\",children:\"4) Tokeniza\\xE7\\xE3o\"}),`\n`,(0,e.jsx)(a.p,{children:\"Adicionamos um token na sequ\\xEAncia de patchs e produzir uma sa\\xEDda para o modelo.\"}),`\n`,(0,e.jsx)(o,{rounded:!0,width:600,height:400,caption:\"Rela\\xE7\\xE3o dos blocos\",src:\"/blog/transformer/equations.png\"}),`\n`,(0,e.jsx)(a.h3,{id:\"para-mais-detalhes\",children:\"Para mais detalhes:\"}),`\n`,(0,e.jsx)(a.h4,{id:\"vis\\xE3o-geral-da-equa\\xE7\\xE3o-1\",children:\"Vis\\xE3o geral da Equa\\xE7\\xE3o 1\"}),`\n`,(0,e.jsx)(r,{caption:\"Equa\\xE7\\xE3o Z0\",children:\"Z_0 = [X_{class}; X_{2p}E; ...;X_{np}E]+E_{pos}, E R^{(p^2*C)^D}, E_{pos} R^{(N*1)^D}\"}),`\n`,(0,e.jsxs)(a.p,{children:[`Equa\\xE7\\xE3o da tokeniza\\xE7\\xE3o !!!, onde enfim incorpora os patchs e a posi\\xE7\\xE3o nos valores de entradas.\n`,(0,e.jsx)(a.code,{children:\"O valores de entradas podem ser uma imagem, textou ou qualquer outro tipo de dado.\"})]}),`\n`,(0,e.jsx)(a.p,{children:\"Um pseudoc\\xF3digo:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-python\",children:(0,e.jsxs)(a.code,{className:\"language-python code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"x_input \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\" \",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"[\"}),\"class_token\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\",\"}),\" image_patch_1\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\",\"}),\" image_patch_2\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\",\"}),\" image_patch_3\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"]\"}),\" \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"+\"}),` \n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"[\"}),\"class_token_position\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\",\"}),\" image_patch_1_position\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\",\"}),\" image_patch_2_position\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\",\"}),` \n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"image_patch_3_position\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"]\"}),`\n`]})]})}),`\n`,(0,e.jsxs)(a.p,{children:[\"Onde cada vetor dessa lista/vetor pode ser aprendido. \",(0,e.jsx)(a.code,{children:\"requires_grad=True\"})]}),`\n`,(0,e.jsx)(a.h4,{id:\"vis\\xE3o-geral-da-equa\\xE7\\xE3o-2\",children:\"Vis\\xE3o geral da Equa\\xE7\\xE3o 2\"}),`\n`,(0,e.jsx)(r,{caption:\"Equa\\xE7\\xE3o Zl\",children:\"Z_l = MSA(LN(Z_{l-1})) + Z_{l-1}, l=1...L\"}),`\n`,(0,e.jsx)(a.p,{children:`Nessa equa\\xE7\\xE3o mostra que para cada camada, existe um MSA envolvendo uma camada layer norm (LN).\nA adi\\xE7\\xE3o final \\xE9 uma conex\\xE3o residual, que \\xE9 basicamente adicionar as informa\\xE7\\xF5es originais a sa\\xEDda. Ou seja, o modelo\ndiz simplesmente:`}),`\n`,(0,e.jsxs)(a.blockquote,{children:[`\n`,(0,e.jsx)(a.p,{children:\"Mantenha parte da informa\\xE7\\xE3o original, pois ela pode ser \\xFAtil!\"}),`\n`]}),`\n`,(0,e.jsx)(o,{rounded:!0,width:600,height:400,caption:\"Conex\\xE3o residual\",src:\"/blog/transformer/residual.png\"}),`\n`,(0,e.jsx)(a.p,{children:\"Um pseudoc\\xF3digo:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-python\",children:(0,e.jsx)(a.code,{className:\"language-python code-highlight\",children:(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"x_output_MSA_block \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\" MSA_layer\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"(\"}),\"LN_layer\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"(\"}),\"x_input\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\")\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\")\"}),\" \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"+\"}),` x_input\n`]})})}),`\n`,(0,e.jsx)(a.h4,{id:\"vis\\xE3o-geral-da-equa\\xE7\\xE3o-3\",children:\"Vis\\xE3o geral da Equa\\xE7\\xE3o 3\"}),`\n`,(0,e.jsx)(r,{caption:\"Equa\\xE7\\xE3o Zl\",children:\"Z_l = MLP(LN(Z_{l}')) + Z_{l}, l=1...L\"}),`\n`,(0,e.jsx)(a.p,{children:\"A equa\\xE7\\xE3o \\xE9 quase o mesmo que a equa\\xE7\\xE3o 2, por\\xE9m com uma MLP (Multi Layer Perception) no final, ao inv\\xE9s de uma MSA, envolto de uma (LN).\"}),`\n`,(0,e.jsx)(a.p,{children:\"Um pseudoc\\xF3digo:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-python\",children:(0,e.jsx)(a.code,{className:\"language-python code-highlight\",children:(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"x_output_MLP_block \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\" MLP_layer\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"(\"}),\"LN_layer\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"(\"}),\"x_output_MSA_block\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\")\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\")\"}),\" \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"+\"}),` x_output_MSA_block\n`]})})}),`\n`,(0,e.jsx)(a.h4,{id:\"vis\\xE3o-geral-da-equa\\xE7\\xE3o-4\",children:\"Vis\\xE3o geral da Equa\\xE7\\xE3o 4\"}),`\n`,(0,e.jsx)(r,{caption:\"Equa\\xE7\\xE3o final\",children:\"y = LN(Z_l^0)\"}),`\n`,(0,e.jsx)(a.p,{children:\"Para \\xFAltima camada, a sa\\xEDda \\xE9 um token de \\xEDndice 0, envolto de uma camada (LN).\"}),`\n`,(0,e.jsx)(a.p,{children:\"Um pseudoc\\xF3digo:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-python\",children:(0,e.jsx)(a.code,{className:\"language-python code-highlight\",children:(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"y \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\" Linear_layer\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"(\"}),\"LN_layer\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"(\"}),\"x_output_MLP_block\",(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"[\"}),(0,e.jsx)(a.span,{className:\"token number\",children:\"0\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\"]\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\")\"}),(0,e.jsx)(a.span,{className:\"token punctuation\",children:\")\"}),`\n`]})})})]})}function v(n={}){let{wrapper:a}=n.components||{};return a?(0,e.jsx)(a,Object.assign({},n,{children:(0,e.jsx)(l,n)})):l(n)}var M=v;function p(n,a){throw new Error(\"Expected \"+(a?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return q(x);})();\n;return Component;"
  },
  "_id": "blog/transformer.mdx",
  "_raw": {
    "sourceFilePath": "blog/transformer.mdx",
    "sourceFileName": "transformer.mdx",
    "sourceFileDir": "blog",
    "contentType": "mdx",
    "flattenedPath": "blog/transformer"
  },
  "type": "Post",
  "slug": "transformer",
  "image": "/blog/transformer/image.jpeg",
  "og": "/blog/transformer/image.jpeg"
}